{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from clientClass import *\n",
    "from dataFunction import *\n",
    "from HE_functions import *\n",
    "import tenseal as ts\n",
    "RANDOM_STATE = 123\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "torch.random.manual_seed(11007303)\n",
    "random.seed(11007303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 4\n",
    "n_features = 18\n",
    "glob_model = LR(n_features)\n",
    "EPOCHS = 80\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframes for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleveland = \"FL_HE_2/processed.cleveland.data\"\n",
    "switzerland = \"FL_HE_2/processed.switzerland.data\"\n",
    "va = \"FL_HE_2/processed.va.data\"\n",
    "hungarian = \"FL_HE_2/reprocessed.hungarian.data\"\n",
    "cleveland_df, switzerland_df, va_df, hungarian_df = import_data(cleveland, switzerland, va, hungarian)\n",
    "df_dict ={\n",
    "    'Cleveland': cleveland_df,\n",
    "    'Switzerland': switzerland_df,\n",
    "    'VA Long Beach': va_df,\n",
    "    'Hungary': hungarian_df        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for i in clients:\n",
    "#     plt.hist(i.y)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "    df_dict[i] = new_df(df)\n",
    "    location_data = new_df(df)\n",
    "    y = location_data.HeartDisease\n",
    "    location_data = location_data.drop(columns=\"HeartDisease\")\n",
    "    cat_feat = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "    location_data = make_dummies(location_data, cat_feat)\n",
    "    numeric_feature_names = ['Age', 'MaxHR', 'RestingBP',  'Cholesterol', 'Oldpeak']\n",
    "    for j in numeric_feature_names:\n",
    "        if location_data[j].std() != 0: \n",
    "            location_data[j] = (location_data[j] - location_data[j].mean()) / location_data[j].std()\n",
    "    x = location_data\n",
    "    client_model = copy.deepcopy(glob_model)\n",
    "    lr = 3\n",
    "    lr_decay = 1\n",
    "    clients.append(Client(i, x, y, cat_feat, client_model, lr, torch.nn.BCELoss()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X_set = torch.tensor(())\n",
    "validation_y_set = torch.tensor(())\n",
    "for i in range(len(clients)):\n",
    "    validation_X_set = torch.cat((validation_X_set, clients[i].X_test), 0)\n",
    "    validation_y_set = torch.cat((validation_y_set, clients[i].y_test), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(validation_y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.749, Test loss 0.586, Test accuracy: 0.83\n",
      "Round   1, Average loss 0.728, Test loss 0.445, Test accuracy: 0.80\n",
      "Round   2, Average loss 0.636, Test loss 0.440, Test accuracy: 0.87\n",
      "Round   3, Average loss 0.588, Test loss 0.451, Test accuracy: 0.83\n",
      "Round   4, Average loss 0.558, Test loss 0.450, Test accuracy: 0.87\n",
      "Round   5, Average loss 0.538, Test loss 0.457, Test accuracy: 0.83\n",
      "Round   6, Average loss 0.523, Test loss 0.457, Test accuracy: 0.83\n",
      "Round   7, Average loss 0.512, Test loss 0.461, Test accuracy: 0.83\n",
      "Round   8, Average loss 0.503, Test loss 0.462, Test accuracy: 0.83\n",
      "Round   9, Average loss 0.496, Test loss 0.465, Test accuracy: 0.83\n",
      "Round  10, Average loss 0.489, Test loss 0.467, Test accuracy: 0.83\n",
      "Round  11, Average loss 0.484, Test loss 0.470, Test accuracy: 0.83\n",
      "Round  12, Average loss 0.480, Test loss 0.471, Test accuracy: 0.83\n",
      "Round  13, Average loss 0.476, Test loss 0.474, Test accuracy: 0.83\n",
      "Round  14, Average loss 0.472, Test loss 0.475, Test accuracy: 0.83\n",
      "Round  15, Average loss 0.469, Test loss 0.477, Test accuracy: 0.83\n",
      "Round  16, Average loss 0.467, Test loss 0.479, Test accuracy: 0.83\n",
      "Round  17, Average loss 0.464, Test loss 0.481, Test accuracy: 0.83\n",
      "Round  18, Average loss 0.462, Test loss 0.483, Test accuracy: 0.83\n",
      "Round  19, Average loss 0.460, Test loss 0.485, Test accuracy: 0.83\n",
      "Round  20, Average loss 0.458, Test loss 0.487, Test accuracy: 0.83\n",
      "Round  21, Average loss 0.456, Test loss 0.489, Test accuracy: 0.83\n",
      "Round  22, Average loss 0.454, Test loss 0.490, Test accuracy: 0.83\n",
      "Round  23, Average loss 0.453, Test loss 0.492, Test accuracy: 0.83\n",
      "Round  24, Average loss 0.451, Test loss 0.494, Test accuracy: 0.83\n",
      "Round  25, Average loss 0.450, Test loss 0.496, Test accuracy: 0.83\n",
      "Round  26, Average loss 0.449, Test loss 0.497, Test accuracy: 0.83\n",
      "Round  27, Average loss 0.448, Test loss 0.499, Test accuracy: 0.83\n",
      "Round  28, Average loss 0.447, Test loss 0.501, Test accuracy: 0.83\n",
      "Round  29, Average loss 0.446, Test loss 0.502, Test accuracy: 0.83\n",
      "Round  30, Average loss 0.445, Test loss 0.504, Test accuracy: 0.83\n",
      "Round  31, Average loss 0.444, Test loss 0.506, Test accuracy: 0.83\n",
      "Round  32, Average loss 0.443, Test loss 0.507, Test accuracy: 0.83\n",
      "Round  33, Average loss 0.442, Test loss 0.509, Test accuracy: 0.83\n",
      "Round  34, Average loss 0.441, Test loss 0.510, Test accuracy: 0.83\n",
      "Round  35, Average loss 0.440, Test loss 0.512, Test accuracy: 0.83\n",
      "Round  36, Average loss 0.440, Test loss 0.514, Test accuracy: 0.83\n",
      "Round  37, Average loss 0.439, Test loss 0.515, Test accuracy: 0.83\n",
      "Round  38, Average loss 0.438, Test loss 0.516, Test accuracy: 0.83\n",
      "Round  39, Average loss 0.437, Test loss 0.518, Test accuracy: 0.83\n",
      "Round  40, Average loss 0.437, Test loss 0.520, Test accuracy: 0.83\n",
      "Round  41, Average loss 0.436, Test loss 0.521, Test accuracy: 0.83\n",
      "Round  42, Average loss 0.436, Test loss 0.523, Test accuracy: 0.83\n",
      "Round  43, Average loss 0.435, Test loss 0.524, Test accuracy: 0.83\n",
      "Round  44, Average loss 0.435, Test loss 0.526, Test accuracy: 0.83\n",
      "Round  45, Average loss 0.434, Test loss 0.528, Test accuracy: 0.83\n",
      "Round  46, Average loss 0.434, Test loss 0.529, Test accuracy: 0.83\n",
      "Round  47, Average loss 0.433, Test loss 0.531, Test accuracy: 0.83\n",
      "Round  48, Average loss 0.433, Test loss 0.532, Test accuracy: 0.83\n",
      "Round  49, Average loss 0.432, Test loss 0.533, Test accuracy: 0.83\n",
      "Best model, iter: 2, acc: 0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "loss_train = []\n",
    "net_best = None\n",
    "best_acc = None\n",
    "best_epoch = None\n",
    "results = []\n",
    "min_loss_client = []\n",
    "glob_model = LR(n_features)\n",
    "glob_model.eval()\n",
    "for iter in range(50):\n",
    "    loss_locals = []\n",
    "    client_state_dicts = []\n",
    "    for client in clients:\n",
    "        client.set_state_dict(glob_model.state_dict())\n",
    "        client_state_dict, loss = client.train()\n",
    "        \n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "        min_loss_client.append(min(loss))\n",
    "        client_state_dicts.append(client_state_dict)\n",
    "\n",
    "    enrypted_state_dicts = encrypt_state_dicts(copy.deepcopy(client_state_dicts), ctx_eval)\n",
    "    averaged_encrypted_state_dict = average_state_dict(enrypted_state_dicts)\n",
    "    decrypted_state_dicts = decrypt_state_dicts(averaged_encrypted_state_dict)\n",
    "    glob_model.load_state_dict(decrypted_state_dicts)\n",
    "\n",
    "    loss_avg = sum(min_loss_client) / len(min_loss_client)\n",
    "    loss_train.append(loss_avg)        \n",
    "        \n",
    "    acc_test, loss_test =  accuracy_loss_LR(glob_model,validation_X_set, validation_y_set)\n",
    "\n",
    "    print('Round {:3d}, Average loss {:.3f}, Test loss {:.3f}, Test accuracy: {:.2f}'.format(\n",
    "        iter, loss_avg, loss_test, acc_test))\n",
    "\n",
    "\n",
    "    if best_acc is None or acc_test > best_acc:\n",
    "        net_best = copy.deepcopy(glob_model)\n",
    "        best_acc = acc_test\n",
    "        best_epoch = iter\n",
    "\n",
    "    results.append(np.array([iter, loss_avg, loss_test, acc_test, best_acc]))\n",
    "    final_results = np.array(results)\n",
    "    final_results = pd.DataFrame(final_results, columns=['epoch', 'loss_avg', 'loss_test', 'acc_test', 'best_acc'])\n",
    "\n",
    "print('Best model, iter: {}, acc: {}'.format(best_epoch, best_acc))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3170,  2.6666, -0.0312,  0.5973,  1.1402, -0.1384,  2.0627,  0.5769,\n",
       "         -0.7088,  1.0325, -0.5087, -0.5086, -0.4269, -1.0707,  0.2741, -0.7073,\n",
       "          1.0230, -0.9730]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted_state_dicts['lr.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3118,  2.6255, -0.0302,  0.5887,  1.1231, -0.1367,  2.0303,  0.5687,\n",
       "         -0.6987,  1.0165, -0.5007, -0.5003, -0.4200, -1.0533,  0.2697, -0.6958,\n",
       "          1.0056, -0.9577]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_state_dict['lr.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0047]])\n",
      "tensor([0.0006])\n"
     ]
    }
   ],
   "source": [
    "averaged_state_dict = average_state_dict(client_state_dicts)\n",
    "for key in decrypted_state_dicts.keys():\n",
    "    if key == 'lr.weight':\n",
    "        Distance  = torch.cdist(decrypted_state_dicts['lr.weight'],averaged_state_dict['lr.weight'])**2\n",
    "    else:\n",
    "        Distance = ((decrypted_state_dicts[key]-averaged_state_dict[key])**2)\n",
    "    print(Distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69650470d3dba1dfb0173b7d578c7df4bae2b2f16b8279109af7c296623678fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis_fl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
