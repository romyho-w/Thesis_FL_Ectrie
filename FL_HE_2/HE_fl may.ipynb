{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from clientClass import *\n",
    "from dataFunction import *\n",
    "from HE_functions import *\n",
    "import tenseal as ts\n",
    "from cryptotree.preprocessing import Featurizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "RANDOM_STATE = 123\n",
    "from collections import OrderedDict\n",
    "from base64 import b64encode, b64decode\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.special import expit\n",
    "from functools import reduce\n",
    "torch.random.manual_seed(11007303)\n",
    "random.seed(11007303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 4\n",
    "n_features = 18\n",
    "glob_model = LR(n_features)\n",
    "EPOCHS = 80\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframes for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleveland = \"FL_HE_2/processed.cleveland.data\"\n",
    "switzerland = \"FL_HE_2/processed.switzerland.data\"\n",
    "va = \"FL_HE_2/processed.va.data\"\n",
    "hungarian = \"FL_HE_2/reprocessed.hungarian.data\"\n",
    "cleveland_df, switzerland_df, va_df, hungarian_df = import_data(cleveland, switzerland, va, hungarian)\n",
    "df_dict ={\n",
    "    'Cleveland': cleveland_df,\n",
    "    'Switzerland': switzerland_df,\n",
    "    'VA Long Beach': va_df,\n",
    "    'Hungary': hungarian_df        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "    df_dict[i] = new_df(df)\n",
    "    location_data = new_df(df)\n",
    "    y = location_data.HeartDisease\n",
    "    location_data = location_data.drop(columns=\"HeartDisease\")\n",
    "    cat_feat = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "    location_data = make_dummies(location_data, cat_feat)\n",
    "    numeric_feature_names = ['Age', 'MaxHR', 'RestingBP',  'Cholesterol', 'Oldpeak']\n",
    "    for j in numeric_feature_names:\n",
    "        if location_data[j].std() != 0: \n",
    "            location_data[j] = (location_data[j] - location_data[j].mean()) / location_data[j].std()\n",
    "    x = location_data\n",
    "    client_model = copy.deepcopy(glob_model)\n",
    "    lr = 3\n",
    "    lr_decay = 1\n",
    "    clients.append(Client(i, x, y, cat_feat, client_model, lr, torch.nn.BCELoss()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X_set = torch.tensor(())\n",
    "validation_y_set = torch.tensor(())\n",
    "for i in range(len(clients)):\n",
    "    validation_X_set = torch.cat((validation_X_set, clients[i].X_test), 0)\n",
    "    validation_y_set = torch.cat((validation_y_set, clients[i].y_test), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.696, Test loss 0.659, Test accuracy: 0.64\n",
      "Round   1, Average loss 0.625, Test loss 0.547, Test accuracy: 0.71\n",
      "Round   2, Average loss 0.582, Test loss 0.560, Test accuracy: 0.69\n",
      "Round   3, Average loss 0.555, Test loss 0.530, Test accuracy: 0.75\n",
      "Round   4, Average loss 0.536, Test loss 0.537, Test accuracy: 0.72\n",
      "Round   5, Average loss 0.522, Test loss 0.529, Test accuracy: 0.75\n",
      "Round   6, Average loss 0.511, Test loss 0.532, Test accuracy: 0.74\n",
      "Round   7, Average loss 0.502, Test loss 0.530, Test accuracy: 0.74\n",
      "Round   8, Average loss 0.495, Test loss 0.531, Test accuracy: 0.74\n",
      "Round   9, Average loss 0.489, Test loss 0.531, Test accuracy: 0.74\n",
      "Round  10, Average loss 0.484, Test loss 0.532, Test accuracy: 0.74\n",
      "Round  11, Average loss 0.480, Test loss 0.533, Test accuracy: 0.74\n",
      "Round  12, Average loss 0.476, Test loss 0.533, Test accuracy: 0.74\n",
      "Round  13, Average loss 0.473, Test loss 0.534, Test accuracy: 0.74\n",
      "Round  14, Average loss 0.470, Test loss 0.535, Test accuracy: 0.74\n",
      "Round  15, Average loss 0.467, Test loss 0.535, Test accuracy: 0.74\n",
      "Round  16, Average loss 0.465, Test loss 0.536, Test accuracy: 0.74\n",
      "Round  17, Average loss 0.463, Test loss 0.537, Test accuracy: 0.74\n",
      "Round  18, Average loss 0.461, Test loss 0.538, Test accuracy: 0.74\n",
      "Round  19, Average loss 0.459, Test loss 0.539, Test accuracy: 0.74\n",
      "Round  20, Average loss 0.457, Test loss 0.540, Test accuracy: 0.74\n",
      "Round  21, Average loss 0.456, Test loss 0.540, Test accuracy: 0.74\n",
      "Round  22, Average loss 0.455, Test loss 0.541, Test accuracy: 0.74\n",
      "Round  23, Average loss 0.453, Test loss 0.542, Test accuracy: 0.74\n",
      "Round  24, Average loss 0.452, Test loss 0.543, Test accuracy: 0.74\n",
      "Round  25, Average loss 0.451, Test loss 0.544, Test accuracy: 0.74\n",
      "Round  26, Average loss 0.450, Test loss 0.545, Test accuracy: 0.74\n",
      "Round  27, Average loss 0.449, Test loss 0.546, Test accuracy: 0.74\n",
      "Round  28, Average loss 0.448, Test loss 0.547, Test accuracy: 0.75\n",
      "Round  29, Average loss 0.447, Test loss 0.548, Test accuracy: 0.75\n",
      "Round  30, Average loss 0.447, Test loss 0.548, Test accuracy: 0.75\n",
      "Round  31, Average loss 0.446, Test loss 0.549, Test accuracy: 0.75\n",
      "Round  32, Average loss 0.445, Test loss 0.550, Test accuracy: 0.75\n",
      "Round  33, Average loss 0.445, Test loss 0.551, Test accuracy: 0.75\n",
      "Round  34, Average loss 0.444, Test loss 0.552, Test accuracy: 0.75\n",
      "Round  35, Average loss 0.443, Test loss 0.553, Test accuracy: 0.75\n",
      "Round  36, Average loss 0.443, Test loss 0.554, Test accuracy: 0.75\n",
      "Round  37, Average loss 0.442, Test loss 0.555, Test accuracy: 0.75\n",
      "Round  38, Average loss 0.442, Test loss 0.555, Test accuracy: 0.76\n",
      "Round  39, Average loss 0.441, Test loss 0.556, Test accuracy: 0.75\n",
      "Round  40, Average loss 0.441, Test loss 0.557, Test accuracy: 0.76\n",
      "Round  41, Average loss 0.441, Test loss 0.558, Test accuracy: 0.75\n",
      "Round  42, Average loss 0.440, Test loss 0.559, Test accuracy: 0.75\n",
      "Round  43, Average loss 0.440, Test loss 0.560, Test accuracy: 0.75\n",
      "Round  44, Average loss 0.440, Test loss 0.560, Test accuracy: 0.75\n",
      "Round  45, Average loss 0.439, Test loss 0.561, Test accuracy: 0.75\n",
      "Round  46, Average loss 0.439, Test loss 0.562, Test accuracy: 0.75\n",
      "Round  47, Average loss 0.439, Test loss 0.563, Test accuracy: 0.75\n",
      "Round  48, Average loss 0.439, Test loss 0.564, Test accuracy: 0.75\n",
      "Round  49, Average loss 0.438, Test loss 0.565, Test accuracy: 0.75\n",
      "Round  50, Average loss 0.438, Test loss 0.566, Test accuracy: 0.75\n",
      "Round  51, Average loss 0.438, Test loss 0.567, Test accuracy: 0.75\n",
      "Round  52, Average loss 0.438, Test loss 0.567, Test accuracy: 0.75\n",
      "Round  53, Average loss 0.438, Test loss 0.568, Test accuracy: 0.75\n",
      "Round  54, Average loss 0.437, Test loss 0.569, Test accuracy: 0.75\n",
      "Round  55, Average loss 0.437, Test loss 0.570, Test accuracy: 0.75\n",
      "Round  56, Average loss 0.437, Test loss 0.570, Test accuracy: 0.75\n",
      "Round  57, Average loss 0.437, Test loss 0.571, Test accuracy: 0.75\n",
      "Round  58, Average loss 0.437, Test loss 0.572, Test accuracy: 0.76\n",
      "Round  59, Average loss 0.437, Test loss 0.573, Test accuracy: 0.76\n",
      "Round  60, Average loss 0.437, Test loss 0.574, Test accuracy: 0.76\n",
      "Round  61, Average loss 0.436, Test loss 0.575, Test accuracy: 0.76\n",
      "Round  62, Average loss 0.436, Test loss 0.575, Test accuracy: 0.76\n",
      "Round  63, Average loss 0.436, Test loss 0.576, Test accuracy: 0.76\n",
      "Round  64, Average loss 0.436, Test loss 0.577, Test accuracy: 0.76\n",
      "Round  65, Average loss 0.436, Test loss 0.578, Test accuracy: 0.76\n",
      "Round  66, Average loss 0.436, Test loss 0.578, Test accuracy: 0.76\n",
      "Round  67, Average loss 0.436, Test loss 0.579, Test accuracy: 0.76\n",
      "Round  68, Average loss 0.436, Test loss 0.580, Test accuracy: 0.76\n",
      "Round  69, Average loss 0.436, Test loss 0.581, Test accuracy: 0.76\n",
      "Round  70, Average loss 0.436, Test loss 0.581, Test accuracy: 0.75\n",
      "Round  71, Average loss 0.436, Test loss 0.582, Test accuracy: 0.75\n",
      "Round  72, Average loss 0.436, Test loss 0.583, Test accuracy: 0.75\n",
      "Round  73, Average loss 0.436, Test loss 0.584, Test accuracy: 0.75\n",
      "Round  74, Average loss 0.436, Test loss 0.585, Test accuracy: 0.75\n",
      "Round  75, Average loss 0.436, Test loss 0.585, Test accuracy: 0.75\n",
      "Round  76, Average loss 0.436, Test loss 0.586, Test accuracy: 0.75\n",
      "Round  77, Average loss 0.436, Test loss 0.587, Test accuracy: 0.75\n",
      "Round  78, Average loss 0.436, Test loss 0.588, Test accuracy: 0.75\n",
      "Round  79, Average loss 0.436, Test loss 0.588, Test accuracy: 0.75\n",
      "Best model, iter: 38, acc: 0.7599999904632568\n"
     ]
    }
   ],
   "source": [
    "loss_train = []\n",
    "net_best = None\n",
    "best_acc = None\n",
    "best_epoch = None\n",
    "results = []\n",
    "min_loss_client = []\n",
    "glob_model = LR(n_features)\n",
    "glob_model.eval()\n",
    "for iter in range(EPOCHS):\n",
    "    loss_locals = []\n",
    "    client_state_dicts = []\n",
    "    for client in clients:\n",
    "        client.set_state_dict(glob_model.state_dict())\n",
    "        client_state_dict, loss = client.train()\n",
    "        \n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "        min_loss_client.append(min(loss))\n",
    "        client_state_dicts.append(client_state_dict)\n",
    "\n",
    "    enrypted_state_dicts = encrypt_state_dicts(copy.deepcopy(client_state_dicts), ctx_eval)\n",
    "    averaged_encrypted_state_dict = average_state_dict(enrypted_state_dicts)\n",
    "    decrypted_state_dicts = decrypt_state_dicts(averaged_encrypted_state_dict)\n",
    "    glob_model.load_state_dict(decrypted_state_dicts)\n",
    "\n",
    "    loss_avg = sum(min_loss_client) / len(min_loss_client)\n",
    "    loss_train.append(loss_avg)        \n",
    "        \n",
    "    acc_test, loss_test =  accuracy_loss_LR(glob_model,validation_X_set, validation_y_set)\n",
    "\n",
    "    print('Round {:3d}, Average loss {:.3f}, Test loss {:.3f}, Test accuracy: {:.2f}'.format(\n",
    "        iter, loss_avg, loss_test, acc_test))\n",
    "\n",
    "\n",
    "    if best_acc is None or acc_test > best_acc:\n",
    "        net_best = copy.deepcopy(glob_model)\n",
    "        best_acc = acc_test\n",
    "        best_epoch = iter\n",
    "\n",
    "    results.append(np.array([iter, loss_avg, loss_test, acc_test, best_acc]))\n",
    "    final_results = np.array(results)\n",
    "    final_results = pd.DataFrame(final_results, columns=['epoch', 'loss_avg', 'loss_test', 'acc_test', 'best_acc'])\n",
    "\n",
    "print('Best model, iter: {}, acc: {}'.format(best_epoch, best_acc))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0053]])\n",
      "tensor([0.0004])\n"
     ]
    }
   ],
   "source": [
    "averaged_state_dict = average_state_dict(client_state_dicts)\n",
    "for key in decrypted_state_dicts.keys():\n",
    "    if key == 'lr.weight':\n",
    "        Distance  = torch.cdist(decrypted_state_dicts['lr.weight'],averaged_state_dict['lr.weight'])**2\n",
    "    else:\n",
    "        Distance = ((decrypted_state_dicts[key]-averaged_state_dict[key])**2)\n",
    "    print(Distance)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69650470d3dba1dfb0173b7d578c7df4bae2b2f16b8279109af7c296623678fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis_fl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
