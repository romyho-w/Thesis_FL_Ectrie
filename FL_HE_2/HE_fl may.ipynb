{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "from clientClass import *\n",
    "from dataFunction import *\n",
    "from HE_functions import *\n",
    "import tenseal as ts\n",
    "RANDOM_STATE = 123\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "torch.random.manual_seed(11007303)\n",
    "random.seed(11007303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 4\n",
    "n_features = 18\n",
    "glob_model = LR(n_features)\n",
    "EPOCHS = 80\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframes for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleveland = \"FL_HE_2/processed.cleveland.data\"\n",
    "switzerland = \"FL_HE_2/processed.switzerland.data\"\n",
    "va = \"FL_HE_2/processed.va.data\"\n",
    "hungarian = \"FL_HE_2/reprocessed.hungarian.data\"\n",
    "cleveland_df, switzerland_df, va_df, hungarian_df = import_data(cleveland, switzerland, va, hungarian)\n",
    "df_dict ={\n",
    "    'Cleveland': cleveland_df,\n",
    "    'Switzerland': switzerland_df,\n",
    "    'VA Long Beach': va_df,\n",
    "    'Hungary': hungarian_df        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for i in clients:\n",
    "#     plt.hist(i.y)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "glob_model = LR(n_features)\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "    df_dict[i] = new_df(df)\n",
    "    location_data = new_df(df)\n",
    "    y = location_data.HeartDisease\n",
    "    location_data = location_data.drop(columns=\"HeartDisease\")\n",
    "    cat_feat = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "    location_data = make_dummies(location_data, cat_feat)\n",
    "    numeric_feature_names = ['Age', 'MaxHR', 'RestingBP',  'Cholesterol', 'Oldpeak']\n",
    "    for j in numeric_feature_names:\n",
    "        if location_data[j].std() != 0: \n",
    "            location_data[j] = (location_data[j] - location_data[j].mean()) / location_data[j].std()\n",
    "    x = location_data\n",
    "    # print(ty pe(y))\n",
    "    client_model = copy.deepcopy(glob_model)\n",
    "    lr = 3\n",
    "    lr_decay = 1\n",
    "    clients.append(Client(i, x, y, client_model, lr, torch.nn.BCELoss()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X_set = torch.tensor(())\n",
    "validation_y_set = torch.tensor(())\n",
    "for i in range(len(clients)):\n",
    "    validation_X_set = torch.cat((validation_X_set, clients[i].X_test), 0)\n",
    "    validation_y_set = torch.cat((validation_y_set, clients[i].y_test), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(validation_y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.322, Test loss 0.556, Test accuracy: 0.73\n",
      "Round   1, Average loss 0.320, Test loss 0.545, Test accuracy: 0.75\n",
      "Round   2, Average loss 0.319, Test loss 0.541, Test accuracy: 0.74\n",
      "Round   3, Average loss 0.318, Test loss 0.540, Test accuracy: 0.74\n",
      "Round   4, Average loss 0.317, Test loss 0.540, Test accuracy: 0.74\n",
      "Round   5, Average loss 0.316, Test loss 0.540, Test accuracy: 0.74\n",
      "Round   6, Average loss 0.316, Test loss 0.541, Test accuracy: 0.74\n",
      "Round   7, Average loss 0.316, Test loss 0.541, Test accuracy: 0.74\n",
      "Round   8, Average loss 0.316, Test loss 0.541, Test accuracy: 0.74\n",
      "Round   9, Average loss 0.315, Test loss 0.542, Test accuracy: 0.74\n",
      "Round  10, Average loss 0.315, Test loss 0.542, Test accuracy: 0.74\n",
      "Round  11, Average loss 0.315, Test loss 0.543, Test accuracy: 0.74\n",
      "Round  12, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  13, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  14, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  15, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  16, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  17, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  18, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  19, Average loss 0.315, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  20, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  21, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  22, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  23, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  24, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  25, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  26, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  27, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  28, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  29, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  30, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  31, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  32, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  33, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  34, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  35, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  36, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  37, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  38, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  39, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  40, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  41, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  42, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  43, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  44, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  45, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  46, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  47, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  48, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Round  49, Average loss 0.314, Test loss 0.543, Test accuracy: 0.73\n",
      "Best model, iter: 1, acc: 0.7485714554786682\n"
     ]
    }
   ],
   "source": [
    "loss_train = []\n",
    "net_best = None\n",
    "best_acc = None\n",
    "best_epoch = None\n",
    "results = []\n",
    "min_loss_client = []\n",
    "glob_model = LR(n_features)\n",
    "glob_model.eval()\n",
    "for iter in range(50):\n",
    "    loss_locals = []\n",
    "    client_state_dicts = []\n",
    "    for client in clients:\n",
    "        client.set_state_dict(glob_model.state_dict())\n",
    "        client_state_dict, loss = client.train()\n",
    "        \n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "        min_loss_client.append(min(loss))\n",
    "        client_state_dicts.append(client_state_dict)\n",
    "\n",
    "    enrypted_state_dicts = encrypt_state_dicts(copy.deepcopy(client_state_dicts), ctx_eval)\n",
    "    averaged_encrypted_state_dict = average_state_dict(enrypted_state_dicts)\n",
    "    decrypted_state_dicts = decrypt_state_dicts(averaged_encrypted_state_dict)\n",
    "    glob_model.load_state_dict(decrypted_state_dicts)\n",
    "\n",
    "    loss_avg = sum(min_loss_client) / len(min_loss_client)\n",
    "    loss_train.append(loss_avg)        \n",
    "        \n",
    "    acc_test, loss_test =  accuracy_loss_LR(glob_model,validation_X_set, validation_y_set)\n",
    "\n",
    "    print('Round {:3d}, Average loss {:.3f}, Test loss {:.3f}, Test accuracy: {:.2f}'.format(\n",
    "        iter, loss_avg, loss_test, acc_test))\n",
    "\n",
    "\n",
    "    if best_acc is None or acc_test > best_acc:\n",
    "        net_best = copy.deepcopy(glob_model)\n",
    "        best_acc = acc_test\n",
    "        best_epoch = iter\n",
    "\n",
    "    results.append(np.array([iter, loss_avg, loss_test, acc_test, best_acc]))\n",
    "    final_results = np.array(results)\n",
    "    final_results = pd.DataFrame(final_results, columns=['epoch', 'loss_avg', 'loss_test', 'acc_test', 'best_acc'])\n",
    "\n",
    "print('Best model, iter: {}, acc: {}'.format(best_epoch, best_acc))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69650470d3dba1dfb0173b7d578c7df4bae2b2f16b8279109af7c296623678fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis_fl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
