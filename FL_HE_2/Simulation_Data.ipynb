{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataFunction import *\n",
    "from clientClass import *\n",
    "import diffprivlib.models as dp\n",
    "import numpy as np\n",
    "import copy\n",
    "from make_logreg_data import *\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from FL_utils import *\n",
    "from HE_functions import *\n",
    "from typing import Generator\n",
    "import tenseal as ts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Interval = tuple[Number, Number]\n",
    "\n",
    "random.seed(11007303)\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_clients = 10\n",
    "n_features = 10\n",
    "n_observations = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_model = LR(n_features)\n",
    "EPOCHS = 80\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_overlapping_intervals\n",
    "# make_features\n",
    "# make_labels\n",
    "# KL_divergence\n",
    "# KL_client\n",
    "# create_client\n",
    "\n",
    "# Generate mu, np.random.uniform(total interval)\n",
    "# \n",
    "# cov matrix diagonal, same variance dim\n",
    "# np.eye(5)*3\n",
    "\n",
    "# Generate input samples, np.random.multivariate_normal(mu,covmat)\n",
    "# per client different mu\n",
    "\n",
    "# KL divergence https://statproofbook.g\\ithub.io/P/mvn-kl.html, symmetrisch  (KL(1,2)+KL(2,1))/2\n",
    "# Mate van overlap binnen alle clients, \n",
    "# np.eye(1.5)\n",
    "# client, multivariate normal distribution uses 1xN vector of mu, and NxN matrix of sigma (cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_distribution = []\n",
    "for i in range(n_clients):\n",
    "    random.seed(11007303)\n",
    "    np.random.seed(2021)\n",
    "    mu = np.random.default_rng().uniform(-1,1, n_features)\n",
    "    rand_cov_num = np.random.default_rng().integers(low=1, high=4)\n",
    "    cov = np.diag([rand_cov_num]*n_features)\n",
    "    clients_distribution.append([mu, cov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.default_rng().integers(low=1, high=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(dist1, dist2):\n",
    "    mu1 = dist1[0]\n",
    "    cov1 = dist1[1]\n",
    "\n",
    "    mu2 = dist2[0]\n",
    "    cov2 = dist2[1]\n",
    "\n",
    "    mu_dif = mu2 - mu1\n",
    "    inv_cov2 = np.linalg.inv(cov2)\n",
    "    trace_cov12 = np.matrix.trace(inv_cov2*cov1)\n",
    "    det_cov1 = np.linalg.det(cov1)\n",
    "    det_cov2 = np.linalg.det(cov2)\n",
    "\n",
    "    return 1/2 *( mu_dif.T @ inv_cov2 @ mu_dif+trace_cov12-np.log(det_cov1/det_cov2)-len(mu1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = np.empty((n_clients, n_clients))\n",
    "kl_sym = np.empty((n_clients, n_clients))\n",
    "for i in range(n_clients):\n",
    "    for j in range(n_clients):\n",
    "        kl[i,j] = KL_divergence(clients_distribution[i], clients_distribution[j])\n",
    "        kl_sym[i,j] = (KL_divergence(clients_distribution[i], clients_distribution[j]) +KL_divergence(clients_distribution[j], clients_distribution[i]))/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896710</td>\n",
       "      <td>2.278748</td>\n",
       "      <td>2.064220</td>\n",
       "      <td>0.673314</td>\n",
       "      <td>1.629188</td>\n",
       "      <td>1.144402</td>\n",
       "      <td>6.363325</td>\n",
       "      <td>1.467728</td>\n",
       "      <td>1.162355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.896710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981403</td>\n",
       "      <td>2.016923</td>\n",
       "      <td>0.582119</td>\n",
       "      <td>1.251368</td>\n",
       "      <td>1.191558</td>\n",
       "      <td>7.254065</td>\n",
       "      <td>1.995905</td>\n",
       "      <td>2.369730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.564708</td>\n",
       "      <td>1.366478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.403626</td>\n",
       "      <td>1.443618</td>\n",
       "      <td>1.554487</td>\n",
       "      <td>1.522585</td>\n",
       "      <td>5.032873</td>\n",
       "      <td>1.471273</td>\n",
       "      <td>2.287673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.421689</td>\n",
       "      <td>1.390158</td>\n",
       "      <td>1.403626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117339</td>\n",
       "      <td>1.202224</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>6.183932</td>\n",
       "      <td>2.009755</td>\n",
       "      <td>0.848504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673314</td>\n",
       "      <td>0.582119</td>\n",
       "      <td>2.097113</td>\n",
       "      <td>1.607694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718190</td>\n",
       "      <td>0.707649</td>\n",
       "      <td>7.554651</td>\n",
       "      <td>1.593157</td>\n",
       "      <td>1.757193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.629188</td>\n",
       "      <td>1.251368</td>\n",
       "      <td>2.263417</td>\n",
       "      <td>1.735023</td>\n",
       "      <td>0.718190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035190</td>\n",
       "      <td>8.952933</td>\n",
       "      <td>2.212907</td>\n",
       "      <td>2.278684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.144402</td>\n",
       "      <td>1.191558</td>\n",
       "      <td>2.215564</td>\n",
       "      <td>1.250517</td>\n",
       "      <td>0.707649</td>\n",
       "      <td>1.035190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.011290</td>\n",
       "      <td>2.534408</td>\n",
       "      <td>1.775804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.778524</td>\n",
       "      <td>3.075437</td>\n",
       "      <td>2.715040</td>\n",
       "      <td>3.290570</td>\n",
       "      <td>3.175632</td>\n",
       "      <td>3.641726</td>\n",
       "      <td>3.661179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.372483</td>\n",
       "      <td>2.552613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.024028</td>\n",
       "      <td>1.376146</td>\n",
       "      <td>1.471273</td>\n",
       "      <td>2.009755</td>\n",
       "      <td>1.107647</td>\n",
       "      <td>1.520814</td>\n",
       "      <td>1.735148</td>\n",
       "      <td>2.347758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.317049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.820446</td>\n",
       "      <td>1.625363</td>\n",
       "      <td>2.287673</td>\n",
       "      <td>0.848504</td>\n",
       "      <td>1.217005</td>\n",
       "      <td>1.564665</td>\n",
       "      <td>1.229412</td>\n",
       "      <td>4.708019</td>\n",
       "      <td>1.317049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.896710  2.278748  2.064220  0.673314  1.629188  1.144402   \n",
       "1  0.896710  0.000000  1.981403  2.016923  0.582119  1.251368  1.191558   \n",
       "2  1.564708  1.366478  0.000000  1.403626  1.443618  1.554487  1.522585   \n",
       "3  1.421689  1.390158  1.403626  0.000000  1.117339  1.202224  0.879221   \n",
       "4  0.673314  0.582119  2.097113  1.607694  0.000000  0.718190  0.707649   \n",
       "5  1.629188  1.251368  2.263417  1.735023  0.718190  0.000000  1.035190   \n",
       "6  1.144402  1.191558  2.215564  1.250517  0.707649  1.035190  0.000000   \n",
       "7  2.778524  3.075437  2.715040  3.290570  3.175632  3.641726  3.661179   \n",
       "8  1.024028  1.376146  1.471273  2.009755  1.107647  1.520814  1.735148   \n",
       "9  0.820446  1.625363  2.287673  0.848504  1.217005  1.564665  1.229412   \n",
       "\n",
       "          7         8         9  \n",
       "0  6.363325  1.467728  1.162355  \n",
       "1  7.254065  1.995905  2.369730  \n",
       "2  5.032873  1.471273  2.287673  \n",
       "3  6.183932  2.009755  0.848504  \n",
       "4  7.554651  1.593157  1.757193  \n",
       "5  8.952933  2.212907  2.278684  \n",
       "6  9.011290  2.534408  1.775804  \n",
       "7  0.000000  1.372483  2.552613  \n",
       "8  2.347758  0.000000  1.317049  \n",
       "9  4.708019  1.317049  0.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896710</td>\n",
       "      <td>1.921728</td>\n",
       "      <td>1.742954</td>\n",
       "      <td>0.673314</td>\n",
       "      <td>1.629188</td>\n",
       "      <td>1.144402</td>\n",
       "      <td>4.570924</td>\n",
       "      <td>1.245878</td>\n",
       "      <td>0.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.896710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.673940</td>\n",
       "      <td>1.703540</td>\n",
       "      <td>0.582119</td>\n",
       "      <td>1.251368</td>\n",
       "      <td>1.191558</td>\n",
       "      <td>5.164751</td>\n",
       "      <td>1.686025</td>\n",
       "      <td>1.997546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.921728</td>\n",
       "      <td>1.673940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.403626</td>\n",
       "      <td>1.770366</td>\n",
       "      <td>1.908952</td>\n",
       "      <td>1.869074</td>\n",
       "      <td>3.873957</td>\n",
       "      <td>1.471273</td>\n",
       "      <td>2.287673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.742954</td>\n",
       "      <td>1.703540</td>\n",
       "      <td>1.403626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.362516</td>\n",
       "      <td>1.468623</td>\n",
       "      <td>1.064869</td>\n",
       "      <td>4.737251</td>\n",
       "      <td>2.009755</td>\n",
       "      <td>0.848504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673314</td>\n",
       "      <td>0.582119</td>\n",
       "      <td>1.770366</td>\n",
       "      <td>1.362516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718190</td>\n",
       "      <td>0.707649</td>\n",
       "      <td>5.365141</td>\n",
       "      <td>1.350402</td>\n",
       "      <td>1.487099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.629188</td>\n",
       "      <td>1.251368</td>\n",
       "      <td>1.908952</td>\n",
       "      <td>1.468623</td>\n",
       "      <td>0.718190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035190</td>\n",
       "      <td>6.297330</td>\n",
       "      <td>1.866860</td>\n",
       "      <td>1.921674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.144402</td>\n",
       "      <td>1.191558</td>\n",
       "      <td>1.869074</td>\n",
       "      <td>1.064869</td>\n",
       "      <td>0.707649</td>\n",
       "      <td>1.035190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.336234</td>\n",
       "      <td>2.134778</td>\n",
       "      <td>1.502608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.570924</td>\n",
       "      <td>5.164751</td>\n",
       "      <td>3.873957</td>\n",
       "      <td>4.737251</td>\n",
       "      <td>5.365141</td>\n",
       "      <td>6.297330</td>\n",
       "      <td>6.336234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.860121</td>\n",
       "      <td>3.630316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.245878</td>\n",
       "      <td>1.686025</td>\n",
       "      <td>1.471273</td>\n",
       "      <td>2.009755</td>\n",
       "      <td>1.350402</td>\n",
       "      <td>1.866860</td>\n",
       "      <td>2.134778</td>\n",
       "      <td>1.860121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.317049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991400</td>\n",
       "      <td>1.997546</td>\n",
       "      <td>2.287673</td>\n",
       "      <td>0.848504</td>\n",
       "      <td>1.487099</td>\n",
       "      <td>1.921674</td>\n",
       "      <td>1.502608</td>\n",
       "      <td>3.630316</td>\n",
       "      <td>1.317049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.896710  1.921728  1.742954  0.673314  1.629188  1.144402   \n",
       "1  0.896710  0.000000  1.673940  1.703540  0.582119  1.251368  1.191558   \n",
       "2  1.921728  1.673940  0.000000  1.403626  1.770366  1.908952  1.869074   \n",
       "3  1.742954  1.703540  1.403626  0.000000  1.362516  1.468623  1.064869   \n",
       "4  0.673314  0.582119  1.770366  1.362516  0.000000  0.718190  0.707649   \n",
       "5  1.629188  1.251368  1.908952  1.468623  0.718190  0.000000  1.035190   \n",
       "6  1.144402  1.191558  1.869074  1.064869  0.707649  1.035190  0.000000   \n",
       "7  4.570924  5.164751  3.873957  4.737251  5.365141  6.297330  6.336234   \n",
       "8  1.245878  1.686025  1.471273  2.009755  1.350402  1.866860  2.134778   \n",
       "9  0.991400  1.997546  2.287673  0.848504  1.487099  1.921674  1.502608   \n",
       "\n",
       "          7         8         9  \n",
       "0  4.570924  1.245878  0.991400  \n",
       "1  5.164751  1.686025  1.997546  \n",
       "2  3.873957  1.471273  2.287673  \n",
       "3  4.737251  2.009755  0.848504  \n",
       "4  5.365141  1.350402  1.487099  \n",
       "5  6.297330  1.866860  1.921674  \n",
       "6  6.336234  2.134778  1.502608  \n",
       "7  0.000000  1.860121  3.630316  \n",
       "8  1.860121  0.000000  1.317049  \n",
       "9  3.630316  1.317049  0.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(kl_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(X: np.ndarray, thresholds: list[Number]) -> np.ndarray:\n",
    "    thresholds = np.array(thresholds)[:, None]\n",
    "    return (X @ thresholds) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for i in clients_distribution:\n",
    "    samples = np.random.default_rng().multivariate_normal(i[0], i[1], n_observations)\n",
    "    x= pd.DataFrame(samples)\n",
    "    # clients_distribution.append([mu, cov])\n",
    "    weights = np.random.default_rng().integers(low=-10, high=10, size=n_features)\n",
    "    y = make_labels(x, weights ).replace({True: 1, False: 0})\n",
    "    # print(type(y.astype(int)))\n",
    "    lr = 3\n",
    "    lr_decay = 1\n",
    "    client_model = copy.deepcopy(glob_model)\n",
    "    clients.append(Client(i, x, y, client_model, lr, torch.nn.BCELoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X_set = torch.tensor(())\n",
    "validation_y_set = torch.tensor(())\n",
    "for i in range(len(clients)):\n",
    "    validation_X_set = torch.cat((validation_X_set, clients[i].X_test), 0)\n",
    "    validation_y_set = torch.cat((validation_y_set, clients[i].y_test), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.110, Test loss 0.744, Test accuracy: 0.66\n",
      "Round   1, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   2, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   3, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   4, Average loss 0.110, Test loss 0.749, Test accuracy: 0.66\n",
      "Round   5, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   6, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   7, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   8, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round   9, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  10, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  11, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  12, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  13, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  14, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  15, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  16, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  17, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  18, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  19, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  20, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  21, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  22, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  23, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  24, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  25, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  26, Average loss 0.110, Test loss 0.749, Test accuracy: 0.66\n",
      "Round  27, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  28, Average loss 0.110, Test loss 0.749, Test accuracy: 0.66\n",
      "Round  29, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  30, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  31, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  32, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  33, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  34, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  35, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  36, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  37, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  38, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  39, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  40, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  41, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  42, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  43, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  44, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  45, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  46, Average loss 0.110, Test loss 0.749, Test accuracy: 0.66\n",
      "Round  47, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  48, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Round  49, Average loss 0.110, Test loss 0.750, Test accuracy: 0.66\n",
      "Best model, iter: 1, acc: 0.6610000133514404\n"
     ]
    }
   ],
   "source": [
    "def FL_proces(clients, validation_X_set, validation_y_set):\n",
    "    loss_train = []\n",
    "    net_best = None\n",
    "    best_acc = None\n",
    "    best_epoch = None\n",
    "    results = []\n",
    "    min_loss_client = []\n",
    "    glob_model = LR(n_features)\n",
    "    glob_model.eval()\n",
    "    enrypted_state_dicts= None\n",
    "    for iter in range(50):\n",
    "        loss_locals = []\n",
    "        client_state_dicts = []\n",
    "        for client in clients:\n",
    "            client.set_state_dict(glob_model.state_dict())\n",
    "            client_state_dict, loss = client.train()\n",
    "            \n",
    "            loss_locals.append(copy.deepcopy(loss))\n",
    "            min_loss_client.append(min(loss))\n",
    "            client_state_dicts.append(client_state_dict)\n",
    "\n",
    "        enrypted_state_dicts = encrypt_state_dicts(copy.deepcopy(client_state_dicts), ctx_eval)\n",
    "        averaged_encrypted_state_dict = average_state_dict(enrypted_state_dicts)\n",
    "        decrypted_state_dicts = decrypt_state_dicts(averaged_encrypted_state_dict)\n",
    "        glob_model.load_state_dict(decrypted_state_dicts)\n",
    "\n",
    "        loss_avg = sum(min_loss_client) / len(min_loss_client)\n",
    "        loss_train.append(loss_avg)        \n",
    "            \n",
    "        acc_test, loss_test =  accuracy_loss_LR(glob_model,validation_X_set, validation_y_set)\n",
    "\n",
    "        print('Round {:3d}, Average loss {:.3f}, Test loss {:.3f}, Test accuracy: {:.2f}'.format(\n",
    "            iter, loss_avg, loss_test, acc_test))\n",
    "\n",
    "\n",
    "        if best_acc is None or acc_test > best_acc:\n",
    "            net_best = copy.deepcopy(glob_model)\n",
    "            best_acc = acc_test\n",
    "            best_epoch = iter\n",
    "\n",
    "        results.append(np.array([iter, loss_avg, loss_test, acc_test, best_acc]))\n",
    "        final_results = np.array(results)\n",
    "        final_results = pd.DataFrame(final_results, columns=['epoch', 'loss_avg', 'loss_test', 'acc_test', 'best_acc'])\n",
    "\n",
    "    print('Best model, iter: {}, acc: {}'.format(best_epoch, best_acc))    \n",
    "    return best_epoch, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69650470d3dba1dfb0173b7d578c7df4bae2b2f16b8279109af7c296623678fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis_fl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
