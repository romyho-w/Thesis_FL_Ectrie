{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from clientClass import Client\n",
    "import torch\n",
    "import random\n",
    "from cryptotree.preprocessing import Featurizer\n",
    "from cryptotree.tree import NeuralRandomForest, SigmoidTreeMaker, TanhTreeMaker\n",
    "from cryptotree.polynomials import plot_graph_function_approximation\n",
    "from cryptotree.cryptotree import HomomorphicNeuralRandomForest, HomomorphicTreeEvaluator, HomomorphicTreeFeaturizer\n",
    "from cryptotree.polynomials import polyeval_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.tabular.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "from cryptotree.tree import CrossEntropyLabelSmoothing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from dataFunction import import_data, new_df, data_prep, make_dummies\n",
    "from torch.utils import data\n",
    "from cryptotree.seal_helper import create_seal_globals, append_globals_to_builtins\n",
    "import builtins\n",
    "import tenseal.sealapi as seal\n",
    "# nest_asyncio.apply()\n",
    "# np.random.seed(10)\n",
    "# tf.random.set_seed(10)\n",
    "# tff.framework.set_default_context(tff.backends.native.create_thread_debugging_execution_context(clients_per_thread=50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframes for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleveland = \"processed.cleveland.data\"\n",
    "switzerland = \"processed.switzerland.data\"\n",
    "va = \"processed.va.data\"\n",
    "hungarian = \"reprocessed.hungarian.data\"\n",
    "cleveland_df, switzerland_df, va_df, hungarian_df = import_data(cleveland, switzerland, va, hungarian)\n",
    "df = new_df(cleveland_df, switzerland_df, va_df, hungarian_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarian_df = df[df.Location == 'Hungarian'].drop(columns=['Location'])\n",
    "switzerland_df = df[df.Location == 'Switzerland'].drop(columns=['Location'])\n",
    "cleveland_df = df[df.Location == 'Cleveland'].drop(columns=['Location'])\n",
    "va_df = df[df.Location == 'VA'].drop(columns=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age         Sex     RestingBP   Cholesterol   FastingBS  \\\n",
      "count  3.030000e+02  303.000000  3.030000e+02  3.030000e+02  303.000000   \n",
      "mean  -8.793846e-18    0.679868  4.160588e-16  1.700144e-16    0.148515   \n",
      "std    1.000000e+00    0.467299  1.000000e+00  1.000000e+00    0.356198   \n",
      "min   -2.814459e+00    0.000000 -2.141495e+00 -2.331021e+00    0.000000   \n",
      "25%   -7.123780e-01    0.000000 -6.642009e-01 -6.893626e-01    0.000000   \n",
      "50%    1.727088e-01    1.000000 -9.601098e-02 -1.099538e-01    0.000000   \n",
      "75%    7.258879e-01    1.000000  4.721790e-01  5.467095e-01    0.000000   \n",
      "max    2.496061e+00    1.000000  3.881319e+00  6.128347e+00    1.000000   \n",
      "\n",
      "              MaxHR  ExerciseAngina       Oldpeak  ChestPainType_1.0  \\\n",
      "count  3.030000e+02      303.000000  3.030000e+02         303.000000   \n",
      "mean  -1.443656e-16        0.326733 -1.003964e-16           0.075908   \n",
      "std    1.000000e+00        0.469794  1.000000e+00           0.265288   \n",
      "min   -3.436382e+00        0.000000 -8.953805e-01           0.000000   \n",
      "25%   -7.041424e-01        0.000000 -8.953805e-01           0.000000   \n",
      "50%    1.483164e-01        0.000000 -2.063639e-01           0.000000   \n",
      "75%    7.166224e-01        1.000000  4.826527e-01           0.000000   \n",
      "max    2.290393e+00        1.000000  4.444498e+00           1.000000   \n",
      "\n",
      "       ChestPainType_4.0  ChestPainType_3.0  ChestPainType_2.0  \\\n",
      "count         303.000000         303.000000         303.000000   \n",
      "mean            0.475248           0.283828           0.165017   \n",
      "std             0.500213           0.451600           0.371809   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             0.000000           0.000000           0.000000   \n",
      "50%             0.000000           0.000000           0.000000   \n",
      "75%             1.000000           1.000000           0.000000   \n",
      "max             1.000000           1.000000           1.000000   \n",
      "\n",
      "       RestingECG_2.0  RestingECG_0.0  RestingECG_1.0  ST_Slope_3.0  \\\n",
      "count      303.000000      303.000000      303.000000    303.000000   \n",
      "mean         0.488449        0.498350        0.013201      0.069307   \n",
      "std          0.500693        0.500824        0.114325      0.254395   \n",
      "min          0.000000        0.000000        0.000000      0.000000   \n",
      "25%          0.000000        0.000000        0.000000      0.000000   \n",
      "50%          0.000000        0.000000        0.000000      0.000000   \n",
      "75%          1.000000        1.000000        0.000000      0.000000   \n",
      "max          1.000000        1.000000        1.000000      1.000000   \n",
      "\n",
      "       ST_Slope_2.0  ST_Slope_1.0  \n",
      "count    303.000000    303.000000  \n",
      "mean       0.462046      0.468647  \n",
      "std        0.499382      0.499842  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.000000      0.000000  \n",
      "50%        0.000000      0.000000  \n",
      "75%        1.000000      1.000000  \n",
      "max        1.000000      1.000000  \n",
      "Cleveland\n",
      "                Age         Sex     RestingBP  Cholesterol   FastingBS  \\\n",
      "count  1.220000e+02  122.000000  1.220000e+02          0.0  122.000000   \n",
      "mean   7.280151e-17    0.918033  3.994983e-16          NaN    0.040984   \n",
      "std    1.000000e+00    0.275446  1.000000e+00          NaN    0.199070   \n",
      "min   -2.583221e+00    0.000000 -2.234732e+00          NaN    0.000000   \n",
      "25%   -4.681005e-01    1.000000 -6.768045e-01          NaN    0.000000   \n",
      "50%    8.851022e-02    1.000000 -1.204019e-01          NaN    0.000000   \n",
      "75%    6.451209e-01    1.000000  6.585618e-01          NaN    0.000000   \n",
      "max    2.092309e+00    1.000000  3.106733e+00          NaN    1.000000   \n",
      "\n",
      "              MaxHR  ExerciseAngina       Oldpeak  ChestPainType_1.0  \\\n",
      "count  1.220000e+02      122.000000  1.220000e+02         122.000000   \n",
      "mean  -1.777381e-16        0.442623  2.393350e-16           0.032787   \n",
      "std    1.000000e+00        0.498745  1.000000e+00           0.178813   \n",
      "min   -2.369648e+00        0.000000 -3.139343e+00           0.000000   \n",
      "25%   -6.662465e-01        0.000000 -6.259670e-01           0.000000   \n",
      "50%   -2.145620e-02        0.000000 -1.426254e-01           0.000000   \n",
      "75%    7.099477e-01        1.000000  7.998908e-01           0.000000   \n",
      "max    2.326735e+00        1.000000  2.950761e+00           1.000000   \n",
      "\n",
      "       ChestPainType_4.0  ChestPainType_3.0  ChestPainType_2.0  \\\n",
      "count         122.000000         122.000000         122.000000   \n",
      "mean            0.795082           0.139344           0.032787   \n",
      "std             0.405306           0.347733           0.178813   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             1.000000           0.000000           0.000000   \n",
      "50%             1.000000           0.000000           0.000000   \n",
      "75%             1.000000           0.000000           0.000000   \n",
      "max             1.000000           1.000000           1.000000   \n",
      "\n",
      "       RestingECG_0.0  RestingECG_1.0  RestingECG_2.0  ST_Slope_1.0  \\\n",
      "count      122.000000      122.000000      122.000000    122.000000   \n",
      "mean         0.704918        0.237705        0.057377      0.270492   \n",
      "std          0.457960        0.427433        0.233521      0.446046   \n",
      "min          0.000000        0.000000        0.000000      0.000000   \n",
      "25%          0.000000        0.000000        0.000000      0.000000   \n",
      "50%          1.000000        0.000000        0.000000      0.000000   \n",
      "75%          1.000000        0.000000        0.000000      1.000000   \n",
      "max          1.000000        1.000000        1.000000      1.000000   \n",
      "\n",
      "       ST_Slope_2.0  ST_Slope_3.0  \n",
      "count    122.000000    122.000000  \n",
      "mean       0.631148      0.098361  \n",
      "std        0.484484      0.299030  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.000000      0.000000  \n",
      "50%        1.000000      0.000000  \n",
      "75%        1.000000      0.000000  \n",
      "max        1.000000      1.000000  \n",
      "Switzerland\n",
      "                Age         Sex     RestingBP   Cholesterol   FastingBS  \\\n",
      "count  1.450000e+02  145.000000  1.450000e+02  1.450000e+02  145.000000   \n",
      "mean  -2.698990e-16    0.965517  3.828355e-17 -1.592596e-16    0.324138   \n",
      "std    1.000000e+00    0.183098  1.000000e+00  1.000000e+00    0.469674   \n",
      "min   -2.829644e+00    0.000000 -2.105426e+00 -1.521487e+00    0.000000   \n",
      "25%   -5.509118e-01    1.000000 -7.928349e-01 -1.521487e+00    0.000000   \n",
      "50%    8.206927e-02    1.000000 -2.459222e-01  3.653857e-01    0.000000   \n",
      "75%    4.618579e-01    1.000000  5.197557e-01  6.973355e-01    1.000000   \n",
      "max    2.234205e+00    1.000000  3.035554e+00  2.479382e+00    1.000000   \n",
      "\n",
      "              MaxHR  ExerciseAngina       Oldpeak  ChestPainType_4.0  \\\n",
      "count  1.450000e+02      145.000000  1.450000e+02         145.000000   \n",
      "mean   1.806984e-16        0.648276 -1.531342e-17           0.731034   \n",
      "std    1.000000e+00        0.479164  1.000000e+00           0.444959   \n",
      "min   -2.439468e+00        0.000000 -1.642362e+00           0.000000   \n",
      "25%   -6.647104e-01        0.000000 -1.189103e+00           0.000000   \n",
      "50%   -1.186310e-01        1.000000  1.706757e-01           1.000000   \n",
      "75%    7.915013e-01        1.000000  6.239352e-01           1.000000   \n",
      "max    2.611766e+00        1.000000  2.436973e+00           1.000000   \n",
      "\n",
      "       ChestPainType_3.0  ChestPainType_2.0  ChestPainType_1.0  \\\n",
      "count         145.000000         145.000000         145.000000   \n",
      "mean            0.186207           0.055172           0.027586   \n",
      "std             0.390623           0.229108           0.164352   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             0.000000           0.000000           0.000000   \n",
      "50%             0.000000           0.000000           0.000000   \n",
      "75%             0.000000           0.000000           0.000000   \n",
      "max             1.000000           1.000000           1.000000   \n",
      "\n",
      "       RestingECG_1.0  RestingECG_2.0  RestingECG_0.0  ST_Slope_2.0  \\\n",
      "count      145.000000      145.000000      145.000000    145.000000   \n",
      "mean         0.448276        0.137931        0.413793      0.689655   \n",
      "std          0.499041        0.346023        0.494219      0.464238   \n",
      "min          0.000000        0.000000        0.000000      0.000000   \n",
      "25%          0.000000        0.000000        0.000000      0.000000   \n",
      "50%          0.000000        0.000000        0.000000      1.000000   \n",
      "75%          1.000000        0.000000        1.000000      1.000000   \n",
      "max          1.000000        1.000000        1.000000      1.000000   \n",
      "\n",
      "       ST_Slope_3.0  ST_Slope_1.0  \n",
      "count    145.000000    145.000000  \n",
      "mean       0.200000      0.110345  \n",
      "std        0.401386      0.314405  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.000000      0.000000  \n",
      "50%        0.000000      0.000000  \n",
      "75%        0.000000      0.000000  \n",
      "max        1.000000      1.000000  \n",
      "VA Long Beach\n",
      "                Age         Sex     RestingBP   Cholesterol   FastingBS  \\\n",
      "count  2.930000e+02  293.000000  2.930000e+02  2.930000e+02  293.000000   \n",
      "mean  -4.319639e-17    0.726962 -6.991942e-16 -6.062651e-17    0.068259   \n",
      "std    1.000000e+00    0.446282  1.000000e+00  1.000000e+00    0.252622   \n",
      "min   -2.533271e+00    0.000000 -2.312726e+00 -2.503405e+00    0.000000   \n",
      "25%   -7.441046e-01    0.000000 -7.197781e-01 -5.780939e-01    0.000000   \n",
      "50%    1.504784e-01    1.000000 -1.508680e-01 -1.808075e-01    0.000000   \n",
      "75%    7.894662e-01    1.000000  4.180421e-01  4.304023e-01    0.000000   \n",
      "max    2.323037e+00    1.000000  3.831503e+00  5.411762e+00    1.000000   \n",
      "\n",
      "              MaxHR  ExerciseAngina       Oldpeak  ChestPainType_2.0  \\\n",
      "count  2.930000e+02      293.000000  2.930000e+02         293.000000   \n",
      "mean  -5.134308e-17        0.303754 -4.168073e-18           0.358362   \n",
      "std    1.000000e+00        0.460665  1.000000e+00           0.480340   \n",
      "min   -2.422161e+00        0.000000 -6.465308e-01           0.000000   \n",
      "25%   -7.242289e-01        0.000000 -6.465308e-01           0.000000   \n",
      "50%    3.984056e-02        0.000000 -6.465308e-01           0.000000   \n",
      "75%    6.765651e-01        1.000000  4.529093e-01           1.000000   \n",
      "max    2.162256e+00        1.000000  4.850669e+00           1.000000   \n",
      "\n",
      "       ChestPainType_3.0  ChestPainType_4.0  ChestPainType_1.0  \\\n",
      "count         293.000000         293.000000         293.000000   \n",
      "mean            0.184300           0.419795           0.037543   \n",
      "std             0.388392           0.494370           0.190413   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             0.000000           0.000000           0.000000   \n",
      "50%             0.000000           0.000000           0.000000   \n",
      "75%             0.000000           1.000000           0.000000   \n",
      "max             1.000000           1.000000           1.000000   \n",
      "\n",
      "       RestingECG_0.0  RestingECG_1.0  RestingECG_2.0  ST_Slope_2.0  \\\n",
      "count      293.000000      293.000000      293.000000    293.000000   \n",
      "mean         0.802048        0.177474        0.020478      0.955631   \n",
      "std          0.399138        0.382723        0.141870      0.206265   \n",
      "min          0.000000        0.000000        0.000000      0.000000   \n",
      "25%          1.000000        0.000000        0.000000      1.000000   \n",
      "50%          1.000000        0.000000        0.000000      1.000000   \n",
      "75%          1.000000        0.000000        0.000000      1.000000   \n",
      "max          1.000000        1.000000        1.000000      1.000000   \n",
      "\n",
      "       ST_Slope_1.0  ST_Slope_3.0  \n",
      "count    293.000000    293.000000  \n",
      "mean       0.040956      0.003413  \n",
      "std        0.198527      0.058421  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.000000      0.000000  \n",
      "50%        0.000000      0.000000  \n",
      "75%        0.000000      0.000000  \n",
      "max        1.000000      1.000000  \n",
      "Hungary\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "n_clients = 4\n",
    "df_dict ={\n",
    "    'Cleveland': cleveland_df,\n",
    "    'Switzerland': switzerland_df,\n",
    "    'VA Long Beach': va_df,\n",
    "    'Hungary': hungarian_df        \n",
    "    }\n",
    "clients = []\n",
    "for i in list(df_dict.keys()):\n",
    "    location_data = df_dict.get(i)\n",
    "    y = location_data.HeartDisease\n",
    "    # y =  torch.tensor(location_data[\"HeartDisease\"].values).float().unsqueeze(1)\n",
    "    location_data = location_data.drop(columns=\"HeartDisease\")\n",
    "    cat_feat = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "    location_data = make_dummies(location_data, cat_feat)\n",
    "    numeric_feature_names = ['Age', 'MaxHR', 'RestingBP',  'Cholesterol', 'Oldpeak']\n",
    "    location_data[numeric_feature_names] = (location_data[numeric_feature_names] - location_data[numeric_feature_names].mean()) / location_data[numeric_feature_names].std()\n",
    "    x = location_data\n",
    "    print(x.describe())\n",
    "    print(i)\n",
    "    # x = torch.tensor(location_data.values).float()\n",
    "    clients.append(Client(i, x, y, cat_feat))\n",
    "\n",
    "# clients[1].X.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clients[1].X, clients[1].y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ChestPainType_1.0</th>\n",
       "      <th>ChestPainType_4.0</th>\n",
       "      <th>ChestPainType_3.0</th>\n",
       "      <th>ChestPainType_2.0</th>\n",
       "      <th>RestingECG_0.0</th>\n",
       "      <th>RestingECG_1.0</th>\n",
       "      <th>RestingECG_2.0</th>\n",
       "      <th>ST_Slope_1.0</th>\n",
       "      <th>ST_Slope_2.0</th>\n",
       "      <th>ST_Slope_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.583221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.567049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.360577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.676805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.248877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.432630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.249255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.142625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.137933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.899366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.340716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.915288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.121927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.710816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.080746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.647020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.676805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.137810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.625967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.647020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.364362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.307399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.869664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.326245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.290921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.980987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.326245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.625967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.092309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.658562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Sex  RestingBP  Cholesterol  FastingBS     MaxHR  \\\n",
       "0   -2.583221  1.0  -1.567049          NaN        0.0  0.209513   \n",
       "1   -2.360577  1.0  -0.676805          NaN        0.0  1.248877   \n",
       "2   -2.249255  1.0  -0.009121          NaN        0.0  0.324998   \n",
       "3   -2.137933  1.0  -0.899366          NaN        0.0  0.132524   \n",
       "4   -1.915288  0.0  -1.121927          NaN        0.0  1.710816   \n",
       "..        ...  ...        ...          ...        ...       ...   \n",
       "118  1.647020  1.0  -0.676805          NaN        0.0 -1.137810   \n",
       "119  1.647020  1.0   0.436001          NaN        1.0  1.364362   \n",
       "120  1.869664  1.0   1.326245          NaN        0.0 -0.290921   \n",
       "121  1.980987  0.0   1.326245          NaN        0.0 -0.021456   \n",
       "122  2.092309  1.0   0.658562          NaN        0.0  0.055534   \n",
       "\n",
       "     ExerciseAngina   Oldpeak  ChestPainType_1.0  ChestPainType_4.0  \\\n",
       "0               0.0  0.050711                  1                  0   \n",
       "1               0.0 -0.432630                  0                  1   \n",
       "2               1.0 -0.142625                  0                  1   \n",
       "3               1.0  0.340716                  0                  1   \n",
       "4               0.0  2.080746                  0                  1   \n",
       "..              ...       ...                ...                ...   \n",
       "118             1.0 -0.625967                  0                  1   \n",
       "119             1.0  1.307399                  0                  1   \n",
       "120             0.0  0.920726                  0                  0   \n",
       "121             0.0 -0.625967                  0                  0   \n",
       "122             0.0  0.630721                  0                  0   \n",
       "\n",
       "     ChestPainType_3.0  ChestPainType_2.0  RestingECG_0.0  RestingECG_1.0  \\\n",
       "0                    0                  0               1               0   \n",
       "1                    0                  0               1               0   \n",
       "2                    0                  0               1               0   \n",
       "3                    0                  0               1               0   \n",
       "4                    0                  0               1               0   \n",
       "..                 ...                ...             ...             ...   \n",
       "118                  0                  0               0               1   \n",
       "119                  0                  0               1               0   \n",
       "120                  1                  0               0               0   \n",
       "121                  1                  0               0               1   \n",
       "122                  0                  1               0               1   \n",
       "\n",
       "     RestingECG_2.0  ST_Slope_1.0  ST_Slope_2.0  ST_Slope_3.0  \n",
       "0                 0             1             0             0  \n",
       "1                 0             1             0             0  \n",
       "2                 0             0             1             0  \n",
       "3                 0             0             1             0  \n",
       "4                 0             1             0             0  \n",
       "..              ...           ...           ...           ...  \n",
       "118               0             0             1             0  \n",
       "119               0             0             1             0  \n",
       "120               1             0             1             0  \n",
       "121               0             1             0             0  \n",
       "122               0             1             0             0  \n",
       "\n",
       "[122 rows x 18 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in clients:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encryption methods\n",
    "-   Homomorphic Encryption (HE)\n",
    "-   Differential Privacy (DP)\n",
    "-   Secure Multiparty Computations (SMPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HE\n",
    "- TenSEAL\n",
    "- linear \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        'Initialization'\n",
    "        self.X, self.y = X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.X[index]).float()\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Featurizer(cat_feat)\n",
    "X_train_normalized = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3\n",
    "\n",
    "dilatation_factor = 10\n",
    "polynomial_degree = dilatation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_tree_maker = SigmoidTreeMaker(use_polynomial=True,\n",
    "                                  dilatation_factor=dilatation_factor, polynomial_degree=polynomial_degree)\n",
    "\n",
    "tanh_tree_maker = TanhTreeMaker(use_polynomial=True,\n",
    "                                  dilatation_factor=dilatation_factor, polynomial_degree=polynomial_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, random_state=0)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "rf.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, X_valid_normalized, y_train, y_valid = train_test_split(pipe.transform(X_train), \n",
    "                                                                            y_train,\n",
    "                                                                            train_size=0.8)\n",
    "y_train = y_train.astype(int)\n",
    "y_valid = y_valid.astype(int)\n",
    "train_ds = TabularDataset(X_train_normalized, y_train.values)\n",
    "valid_ds = TabularDataset(X_valid_normalized, y_valid.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ChestPainType_1.0</th>\n",
       "      <th>ChestPainType_4.0</th>\n",
       "      <th>ChestPainType_3.0</th>\n",
       "      <th>ChestPainType_2.0</th>\n",
       "      <th>RestingECG_0.0</th>\n",
       "      <th>RestingECG_1.0</th>\n",
       "      <th>RestingECG_2.0</th>\n",
       "      <th>ST_Slope_1.0</th>\n",
       "      <th>ST_Slope_2.0</th>\n",
       "      <th>ST_Slope_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.00000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033423</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.062006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.14433</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.113402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.985023</td>\n",
       "      <td>0.291636</td>\n",
       "      <td>1.015109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199871</td>\n",
       "      <td>1.022443</td>\n",
       "      <td>0.501929</td>\n",
       "      <td>0.948603</td>\n",
       "      <td>0.174022</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.35325</td>\n",
       "      <td>0.174022</td>\n",
       "      <td>0.468739</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.242145</td>\n",
       "      <td>0.433756</td>\n",
       "      <td>0.482735</td>\n",
       "      <td>0.318731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.360577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.567049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.369648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.075992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.468100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.676805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.637375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.625967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.199832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.756443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.092309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.106733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.326735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.950761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Sex  RestingBP  Cholesterol  FastingBS      MaxHR  \\\n",
       "count  97.000000  97.000000  97.000000         97.0  97.000000  97.000000   \n",
       "mean    0.033423   0.907216   0.062006          0.0   0.041237   0.017832   \n",
       "std     0.985023   0.291636   1.015109          0.0   0.199871   1.022443   \n",
       "min    -2.360577   0.000000  -1.567049          0.0   0.000000  -2.369648   \n",
       "25%    -0.468100   1.000000  -0.676805          0.0   0.000000  -0.637375   \n",
       "50%     0.199832   1.000000  -0.009121          0.0   0.000000   0.017039   \n",
       "75%     0.756443   1.000000   0.658562          0.0   0.000000   0.825433   \n",
       "max     2.092309   1.000000   3.106733          0.0   1.000000   2.326735   \n",
       "\n",
       "       ExerciseAngina    Oldpeak  ChestPainType_1.0  ChestPainType_4.0  \\\n",
       "count       97.000000  97.000000          97.000000          97.000000   \n",
       "mean         0.474227   0.001879           0.030928           0.793814   \n",
       "std          0.501929   0.948603           0.174022           0.406667   \n",
       "min          0.000000  -2.075992           0.000000           0.000000   \n",
       "25%          0.000000  -0.625967           0.000000           1.000000   \n",
       "50%          0.000000  -0.142625           0.000000           1.000000   \n",
       "75%          1.000000   0.630721           0.000000           1.000000   \n",
       "max          1.000000   2.950761           1.000000           1.000000   \n",
       "\n",
       "       ChestPainType_3.0  ChestPainType_2.0  RestingECG_0.0  RestingECG_1.0  \\\n",
       "count           97.00000          97.000000       97.000000       97.000000   \n",
       "mean             0.14433           0.030928        0.680412        0.257732   \n",
       "std              0.35325           0.174022        0.468739        0.439658   \n",
       "min              0.00000           0.000000        0.000000        0.000000   \n",
       "25%              0.00000           0.000000        0.000000        0.000000   \n",
       "50%              0.00000           0.000000        1.000000        0.000000   \n",
       "75%              0.00000           0.000000        1.000000        1.000000   \n",
       "max              1.00000           1.000000        1.000000        1.000000   \n",
       "\n",
       "       RestingECG_2.0  ST_Slope_1.0  ST_Slope_2.0  ST_Slope_3.0  \n",
       "count       97.000000     97.000000     97.000000     97.000000  \n",
       "mean         0.061856      0.247423      0.639175      0.113402  \n",
       "std          0.242145      0.433756      0.482735      0.318731  \n",
       "min          0.000000      0.000000      0.000000      0.000000  \n",
       "25%          0.000000      0.000000      0.000000      0.000000  \n",
       "50%          0.000000      0.000000      1.000000      0.000000  \n",
       "75%          0.000000      0.000000      1.000000      0.000000  \n",
       "max          1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb#ch0000014?line=10'>11</a>\u001b[0m rf\u001b[39m.\u001b[39mfit(X_train_normalized, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb#ch0000014?line=12'>13</a>\u001b[0m estimators \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mestimators_\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb#ch0000014?line=13'>14</a>\u001b[0m sigmoid_neural_rf \u001b[39m=\u001b[39m NeuralRandomForest(estimators, sigmoid_tree_maker)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb#ch0000014?line=14'>15</a>\u001b[0m tanh_neural_rf \u001b[39m=\u001b[39m NeuralRandomForest(estimators, tanh_tree_maker)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_RF.ipynb#ch0000014?line=16'>17</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py:213\u001b[0m, in \u001b[0;36mNeuralRandomForest.__init__\u001b[0;34m(self, trees, tree_maker, weights, trainable_weights, bias, trainable_bias)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=210'>211</a>\u001b[0m n_leaves \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=211'>212</a>\u001b[0m \u001b[39mfor\u001b[39;00m tree \u001b[39min\u001b[39;00m trees:\n\u001b[0;32m--> <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=212'>213</a>\u001b[0m     neural_tree \u001b[39m=\u001b[39m tree_maker\u001b[39m.\u001b[39;49mmake_tree(tree)\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=213'>214</a>\u001b[0m     n_nodes\u001b[39m.\u001b[39mappend(neural_tree\u001b[39m.\u001b[39mcomparator\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=214'>215</a>\u001b[0m     n_leaves\u001b[39m.\u001b[39mappend(neural_tree\u001b[39m.\u001b[39mmatcher\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py:61\u001b[0m, in \u001b[0;36mNeuralTreeMaker.make_tree\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=58'>59</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=59'>60</a>\u001b[0m     create_head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_regression_head\n\u001b[0;32m---> <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=60'>61</a>\u001b[0m neural_tree \u001b[39m=\u001b[39m NeuralDecisionTree(tree, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_linear_leaf_matcher, create_head)\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=61'>62</a>\u001b[0m \u001b[39mreturn\u001b[39;00m neural_tree\n",
      "File \u001b[0;32m~/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py:74\u001b[0m, in \u001b[0;36mNeuralDecisionTree.__init__\u001b[0;34m(self, tree, activation, create_linear_leaf_matcher, create_head)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=69'>70</a>\u001b[0m \u001b[39msuper\u001b[39m(NeuralDecisionTree, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=71'>72</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m activation\n\u001b[0;32m---> <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=73'>74</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomparator \u001b[39m=\u001b[39m create_linear_node_comparator(tree)\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher \u001b[39m=\u001b[39m create_linear_leaf_matcher(tree)\n\u001b[1;32m     <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/tree.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead \u001b[39m=\u001b[39m create_head(tree)\n",
      "File \u001b[0;32m~/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py:119\u001b[0m, in \u001b[0;36mcreate_linear_node_comparator\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=112'>113</a>\u001b[0m     B\u001b[39m.\u001b[39mappend(b)\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=113'>114</a>\u001b[0m \u001b[39m# if len(W) == 0:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=114'>115</a>\u001b[0m \u001b[39m#     W =[0]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=115'>116</a>\u001b[0m \u001b[39m#     B = [0]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=116'>117</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=117'>118</a>\u001b[0m \u001b[39m# print(W)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=118'>119</a>\u001b[0m W \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack(W)\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=119'>120</a>\u001b[0m B \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(B)\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/cryptotree/activations.py?line=121'>122</a>\u001b[0m linear \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(W\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],W\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py:422\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py?line=419'>420</a>\u001b[0m arrays \u001b[39m=\u001b[39m [asanyarray(arr) \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py?line=420'>421</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m arrays:\n\u001b[0;32m--> <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py?line=421'>422</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mneed at least one array to stack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py?line=423'>424</a>\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    <a href='file:///Users/romyho/Documents/Master_Econometrie/Thesis/Python/thesis_fl/lib/python3.9/site-packages/numpy/core/shape_base.py?line=424'>425</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "\n",
    "train_dl = data.DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = data.DataLoader(valid_ds, batch_size=bs)\n",
    "fix_dl = data.DataLoader(train_ds, batch_size=bs, shuffle=False)\n",
    "tree_maker = tanh_tree_maker\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=max_depth, random_state=0)\n",
    "rf.fit(X_train_normalized, y_train)\n",
    "\n",
    "estimators = rf.estimators_\n",
    "sigmoid_neural_rf = NeuralRandomForest(estimators, sigmoid_tree_maker)\n",
    "tanh_neural_rf = NeuralRandomForest(estimators, tanh_tree_maker)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sigmoid_neural_pred = sigmoid_neural_rf(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "    tanh_neural_pred = tanh_neural_rf(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "\n",
    "pred = rf.predict(X_train_normalized)\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "\n",
    "print(f\"Accuracy of sigmoid  : {(sigmoid_neural_pred == y_train).mean()}\")\n",
    "print(f\"Accuracy of tanh : {(tanh_neural_pred == y_train).mean()}\")\n",
    "\n",
    "print(f\"Match between sigmoid and original : {(sigmoid_neural_pred == pred).mean()}\")\n",
    "print(f\"Match between tanh and original : {(tanh_neural_pred == pred).mean()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 55, 100]) False\n",
      "torch.Size([55, 100]) False\n",
      "torch.Size([56, 55, 100]) False\n",
      "torch.Size([56, 100]) False\n",
      "torch.Size([2, 56, 100]) True\n",
      "torch.Size([2, 100]) True\n"
     ]
    }
   ],
   "source": [
    "tree_maker = tanh_tree_maker\n",
    "model = NeuralRandomForest(rf.estimators_, tree_maker=tree_maker)\n",
    "\n",
    "model.freeze_layer(\"comparator\")\n",
    "model.freeze_layer(\"matcher\")\n",
    "\n",
    "for p in model.parameters():\n",
    "    print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='99' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      99.00% [99/100 00:06<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.486942</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.486941</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.486940</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486938</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.486937</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486936</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.486932</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.486929</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.486926</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.486923</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.486919</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.486915</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.486910</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.486904</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.486897</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.486889</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.486880</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.486869</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.486856</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.486841</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.486823</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.486802</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.486778</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.486749</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.486715</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.486676</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.486629</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.486573</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.486508</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.486431</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.486340</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.486232</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.486105</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.485777</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.485567</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.485318</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.485024</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.484265</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.483779</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.483205</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.482529</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.481731</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.480792</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.479689</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.478397</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.476887</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.475127</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.473087</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.470733</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.468034</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.464963</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.461499</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.457635</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.453380</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.448765</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.443846</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.438707</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.433460</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.428236</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.418429</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.414121</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.410360</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.404771</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.403001</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.401898</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.401423</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.401819</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.402408</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.402948</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.403137</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.402605</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.400939</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.397839</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.393140</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.393110</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.389326</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.387380</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.387439</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.387830</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.386315</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.382894</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.390856</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.405879</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.425111</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.441037</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.444270</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.532548</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.630047</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.837086</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.137680</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.510631</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = DataBunch(train_dl, valid_dl,fix_dl=fix_dl)\n",
    "\n",
    "criterion = CrossEntropyLabelSmoothing()\n",
    "\n",
    "learn = Learner(data, model, loss_func=criterion, metrics=accuracy)\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.658476</td>\n",
       "      <td>0.718581</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638974</td>\n",
       "      <td>0.621392</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622615</td>\n",
       "      <td>0.707079</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.605993</td>\n",
       "      <td>0.604869</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.584027</td>\n",
       "      <td>0.572073</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 1.0\n",
      "Accuracy : 0.8057851239669421\n",
      "Same output : 0.8057851239669421\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_train_normalized)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = model(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_train).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 37]\n",
      "438\n"
     ]
    }
   ],
   "source": [
    "dilatation_factor = 16\n",
    "degree = dilatation_factor\n",
    "\n",
    "PRECISION_BITS = 28\n",
    "UPPER_BITS = 9\n",
    "\n",
    "polynomial_multiplications = int(np.ceil(np.log2(degree))) + 1\n",
    "n_polynomials = 2\n",
    "matrix_multiplications = 3\n",
    "\n",
    "depth = matrix_multiplications + polynomial_multiplications * n_polynomials\n",
    "\n",
    "poly_modulus_degree = 16384\n",
    "\n",
    "moduli = [PRECISION_BITS + UPPER_BITS] + (depth) * [PRECISION_BITS] + [PRECISION_BITS + UPPER_BITS]\n",
    "print(moduli)\n",
    "print(sum(moduli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_seal_globals(globals(), poly_modulus_degree, moduli, PRECISION_BITS, use_symmetric_key=False)\n",
    "append_globals_to_builtins(globals(), builtins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_rf = HomomorphicNeuralRandomForest(model)\n",
    "\n",
    "tree_evaluator = HomomorphicTreeEvaluator.from_model(h_rf, tree_maker.coeffs, \n",
    "                                                   polyeval_tree, evaluator, encoder, relin_keys, galois_keys, \n",
    "                                                   scale)\n",
    "\n",
    "homomorphic_featurizer = HomomorphicTreeFeaturizer(h_rf.return_comparator(), encoder, encryptor, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "x = X_train_normalized[i]\n",
    "ctx = homomorphic_featurizer.encrypt(x)\n",
    "\n",
    "outputs = tree_evaluator(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptx = seal.Plaintext()\n",
    "decryptor.decrypt(outputs, ptx)\n",
    "\n",
    "homomorphic_pred = encoder.decode_double(ptx)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Random Forest output : [[0.615485 0.384515]]\n",
      "Neural Random Forest output : tensor([[ 0.3894, -0.0193]])\n",
      "Homomorphic Random Forest output : [0.41237472196418046, -0.015424882056061889]\n"
     ]
    }
   ],
   "source": [
    "x = X_train_normalized[i]\n",
    "\n",
    "pred = rf.predict_proba(x.reshape(1,-1))\n",
    "neural_pred = model(torch.tensor(x).float().unsqueeze(0))\n",
    "\n",
    "print(f\"Original Random Forest output : {pred}\")\n",
    "print(f\"Neural Random Forest output : {neural_pred.detach()}\")\n",
    "print(f\"Homomorphic Random Forest output : {homomorphic_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.core import parallel\n",
    "import multiprocessing\n",
    "import tenseal.sealapi as seal\n",
    "\n",
    "def predict(x):\n",
    "    \"\"\"Performs HRF prediction\"\"\"\n",
    "    \n",
    "    # We first encrypt and evaluate our model on it\n",
    "    ctx = homomorphic_featurizer.encrypt(x)\n",
    "    outputs = tree_evaluator(ctx)\n",
    "    \n",
    "    # We then decrypt it and get the first 2 values which are the classes scores\n",
    "    ptx = seal.Plaintext()\n",
    "    decryptor.decrypt(outputs, ptx)\n",
    "    \n",
    "    homomorphic_pred = encoder.decode_double(ptx)[:2]\n",
    "    homomorphic_pred = np.argmax(homomorphic_pred)\n",
    "    \n",
    "    return homomorphic_pred\n",
    "\n",
    "\n",
    "# # We get the number of cores\n",
    "# cores = multiprocessing.cpu_count()\n",
    "\n",
    "# # We compute the outputs\n",
    "# hrf_pred = parallel(predict, X_valid_normalized, max_workers=cores)\n",
    "\n",
    "# # Because the outputs are unordered we must first sort by index then take the predictions\n",
    "# hrf_pred = np.array(sorted(hrf_pred, key = lambda x:x[0]))[:,1]\n",
    "\n",
    "# hrf_pred = predict(X_valid_normalized,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_pred = []\n",
    "for i in X_valid_normalized:\n",
    "    # print(i)\n",
    "    hrf_pred.append(predict(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for x,y in valid_dl:\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "    outputs.append(pred)\n",
    "    \n",
    "nrf_pred = torch.cat(outputs).argmax(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LogisticRegression()\n",
    "linear.fit(X_train_normalized, y_train)\n",
    "\n",
    "# We compute the linear preds\n",
    "linear_pred = linear.predict(X_valid_normalized)\n",
    "\n",
    "# We compute the random forest predictions\n",
    "rf_pred = rf.predict(X_valid_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, y):\n",
    "    \"\"\"Computes all the metrics between predictions and real values\"\"\"\n",
    "    accuracy = accuracy_score(pred,y)\n",
    "    precision = precision_score(pred,y)\n",
    "    recall = recall_score(pred,y)\n",
    "    f1 = f1_score(pred, y)\n",
    "    return dict(accuracy=accuracy, precision=precision, recall=recall, f1=f1)\n",
    "\n",
    "models = dict(nrf=nrf_pred,hrf=hrf_pred, rf=rf_pred, linear=linear_pred)\n",
    "\n",
    "outputs = []\n",
    "for name, pred in models.items():\n",
    "    metrics = compute_metrics(pred, y_valid)\n",
    "    metrics[\"model\"] = name\n",
    "    outputs.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>nrf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>hrf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>rf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1   model\n",
       "0  0.803279   0.653846  0.850000  0.739130     nrf\n",
       "1  0.803279   0.653846  0.850000  0.739130     hrf\n",
       "2  0.836066   0.769231  0.833333  0.800000      rf\n",
       "3  0.852459   0.807692  0.840000  0.823529  linear"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cac72e2ca1489f7157a7b4a660893ba3b03625a75143f8c8e6188cd9e63cd5e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis_fl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
