{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from clientClass import Client\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# del sys.modules['cryptotree.tree']\n",
    "# del sys.modules['cryptotree.preprocessing']\n",
    "# del sys.modules['cryptotree.polynomials']\n",
    "# del sys.modules['cryptotree.cryptotree']\n",
    "import builtins\n",
    "\n",
    "import tenseal.sealapi as seal\n",
    "from cryptotree.cryptotree import (HomomorphicNeuralRandomForest,\n",
    "                                   HomomorphicTreeEvaluator,\n",
    "                                   HomomorphicTreeFeaturizer)\n",
    "from cryptotree.polynomials import (plot_graph_function_approximation,\n",
    "                                    polyeval_tree)\n",
    "# del sys.modules['cryptotree.seal_helper']\n",
    "from cryptotree.preprocessing import Featurizer\n",
    "from cryptotree.seal_helper import (append_globals_to_builtins,\n",
    "                                    create_seal_globals, print_ctx,\n",
    "                                    print_range_ctx, print_vector)\n",
    "from cryptotree.tree import (CrossEntropyLabelSmoothing, NeuralRandomForest,\n",
    "                             SigmoidTreeMaker, TanhTreeMaker)\n",
    "from dataFunction import data_prep, import_data, make_dummies, new_df\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.tabular.learner import Learner\n",
    "from HE_functions import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torch.utils import data\n",
    "import missingno as msno\n",
    "# nest_asyncio.apply()\n",
    "# np.random.seed(10)\n",
    "# tf.random.set_seed(10)\n",
    "# tff.framework.set_default_context(tff.backends.native.create_thread_debugging_execution_context(clients_per_thread=50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframes for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland = \"processed.cleveland.data\"\n",
    "switzerland = \"processed.switzerland.data\"\n",
    "va = \"processed.va.data\"\n",
    "hungarian = \"reprocessed.hungarian.data\"\n",
    "cleveland_df, switzerland_df, va_df, hungarian_df = import_data(cleveland, switzerland, va, hungarian)\n",
    "# df = new_df(cleveland_df, switzerland_df, va_df, hungarian_df)\n",
    "df_dict ={\n",
    "    'Cleveland': cleveland_df,\n",
    "    'Switzerland': switzerland_df,\n",
    "    'VA Long Beach': va_df,\n",
    "    'Hungary': hungarian_df        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_fl.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_fl.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m clients:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_fl.ipynb#ch0000004?line=1'>2</a>\u001b[0m     sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(i\u001b[39m.\u001b[39my), \u001b[39mlen\u001b[39m(i\u001b[39m.\u001b[39my))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/romyho/Documents/Master_Econometrie/Thesis/Python/HE_fl.ipynb#ch0000004?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(sample)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clients' is not defined"
     ]
    }
   ],
   "source": [
    "for i in clients:\n",
    "    sample = np.random.randint(1/2*len(i.y), len(i.y))\n",
    "    print(sample)\n",
    "    print(chance_of_dead_tree(sample, sum(i.y == 0), sum(i.y == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "n_clients = 4\n",
    "# df_dict ={\n",
    "#     'Cleveland': cleveland_df,\n",
    "#     'Switzerland': switzerland_df,\n",
    "#     'VA Long Beach': va_df,\n",
    "#     'Hungary': hungarian_df        \n",
    "#     }\n",
    "clients = []\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "    df = new_df(df)\n",
    "    location_data = df\n",
    "    # location_data = new_df(df_dict.get(i))\n",
    "    y = location_data.HeartDisease\n",
    "    # y =  torch.tensor(location_data[\"HeartDisease\"].values).float().unsqueeze(1)\n",
    "    location_data = location_data.drop(columns=\"HeartDisease\")\n",
    "    cat_feat = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "    location_data = make_dummies(location_data, cat_feat)\n",
    "    numeric_feature_names = ['Age', 'MaxHR', 'RestingBP',  'Cholesterol', 'Oldpeak']\n",
    "    for j in numeric_feature_names:\n",
    "        if location_data[j].std() != 0: \n",
    "            location_data[j] = (location_data[j] - location_data[j].mean()) / location_data[j].std()\n",
    "    x = location_data\n",
    "    # x = torch.tensor(location_data.values).float()\n",
    "    clients.append(Client(i, x, y, cat_feat))\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(clients[0].X, clients[0].y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sys.modules['HE_functions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients[1].X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (12,8))\n",
    "# artists = plot_tree(switzerland_estimators[1], ax=ax)\n",
    "# for clf in switzerland_estimators:\n",
    "#     # if clf.tree_.node_count < 5:    \n",
    "#     fig, ax = plt.subplots(figsize = (12,8))\n",
    "#     artists = plot_tree(clf, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HE_functions import *\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "dict_outputs = {}\n",
    "feature_imp = {}\n",
    "for i in clients:\n",
    "    pipe = Featurizer(cat_feat)\n",
    "    rf, sigmoid_tree_maker, tanh_tree_maker = set_tree(5, 13)\n",
    "    y_train, y_valid, X_train_normalized, X_valid_normalized = split_prep_data(i, pipe)\n",
    "    train_ds, valid_ds = make_tabularDataset(X_train_normalized, y_train, X_valid_normalized, y_valid)\n",
    "    train_dl, valid_dl, fix_dl = make_dataloader(train_ds, valid_ds)\n",
    "    rf.fit(X_train_normalized, y_train)\n",
    "    estimators = rf.estimators_\n",
    "    print('\\n')\n",
    "    print(''+i.name+ ': results')\n",
    "    print('\\n')\n",
    "\n",
    "    rf, sigmoid_neural_rf, tanh_neural_rf = results_trees(rf, sigmoid_tree_maker, tanh_tree_maker, X_train_normalized, y_train)\n",
    "\n",
    "    model = fine_tune_tree(tanh_tree_maker, rf, train_dl, valid_dl, fix_dl)\n",
    "\n",
    "    pred = rf.predict(X_train_normalized)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        neural_pred = model(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "\n",
    "    print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "    print(f\"Accuracy : {(neural_pred == y_train).mean()}\")\n",
    "    print(f\"Same output : {(neural_pred == pred).mean()}\")\n",
    "    set_config()\n",
    "    tree_evaluator, homomorphic_featurizer = setup_HE(tanh_tree_maker, model)\n",
    "\n",
    "    hrf_pred = HE_RF_pred(X_valid_normalized, homomorphic_featurizer, tree_evaluator)\n",
    "    \n",
    "    nrf_pred = NRF_pred(valid_dl, model)\n",
    "\n",
    "    linear_pred = LIN_pred(X_train_normalized, y_train, X_valid_normalized)\n",
    "\n",
    "    # We compute the random forest predictions\n",
    "    rf_pred = rf.predict(X_valid_normalized)\n",
    "    feature_imp[i.name] = pd.Series(rf.feature_importances_,index=i.X.columns).sort_values(ascending=False)\n",
    "\n",
    "    models = dict(nrf=nrf_pred,hrf=hrf_pred, rf=rf_pred, linear=linear_pred)\n",
    "\n",
    "    outputs = []\n",
    "    for name, pred in models.items():\n",
    "        metrics = compute_metrics(pred, y_valid)\n",
    "        metrics[\"model\"] = name\n",
    "        outputs.append(metrics)\n",
    "    \n",
    "    outputs = pd.DataFrame(outputs)\n",
    "    dict_outputs[i.name] = outputs\n",
    "    # outputs\n",
    "    #     for p in model.parameters():\n",
    "    #         print(p.shape, p.requires_grad)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest problems\n",
    "\n",
    "sample split gives same y values when switzerland dataset is used. Since the heartdisease variable is unevenly divided. \n",
    "\n",
    "P(altijd 1) bij 50 subsamples == 2% als verdeling 114 keer 1 en 8 keer 0\n",
    "\n",
    "\n",
    "\n",
    "P(altijd 1) bij 57 subsamples == 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dict_outputs.keys():\n",
    "    print(i)\n",
    "    print(dict_outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid, X_train_normalized, X_valid_normalized = split_prep_data(clients[1], pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train_normalized[0]\n",
    "ctx = homomorphic_featurizer.encrypt(x)\n",
    "ptx = seal.Plaintext()\n",
    "decryptor.decrypt(ctx, ptx)\n",
    "print(ctx.save('./text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimator = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "estimator.fit(X_train_normalized, y_train)\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "artists = plot_tree(estimator, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf, sigmoid_neural_rf, tanh_neural_rf\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=clients[0].X.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('tab20')\n",
    "plt.rcParams.update({'font.size': 16,})\n",
    "num=1\n",
    "f2= plt.figure(figsize=(50,30))\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "    for var in list(df.columns.array):\n",
    "        ax = f2.add_subplot(4,5,num)\n",
    "        a = np.asarray(df[var].dropna())\n",
    "        ax.hist(a, bins=50, color=palette(num))\n",
    "        ax.set_title(var)\n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleveland\n",
      "0    164\n",
      "1    139\n",
      "Name: HeartDisease, dtype: int64\n",
      "Switzerland\n",
      "1    115\n",
      "0      8\n",
      "Name: HeartDisease, dtype: int64\n",
      "VA Long Beach\n",
      "1    149\n",
      "0     51\n",
      "Name: HeartDisease, dtype: int64\n",
      "Hungary\n",
      "0.0    188\n",
      "1.0    106\n",
      "Name: HeartDisease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "# palette = plt.get_cmap('tab20')\n",
    "# plt.rcParams.update({'font.size': 16,})\n",
    "# num=1\n",
    "# plt.show()\n",
    "# f2= plt.figure(figsize=(50,30))\n",
    "for i in list(df_dict.keys()):\n",
    "    df = df_dict.get(i)\n",
    "#     # for var in list(df.columns.array):\n",
    "#     ax = f2.add_subplot(4,5,num)\n",
    "#     a = np.asarray(df.HeartDisease.dropna())\n",
    "#     ax.hist(a, bins=50, color=palette(num))\n",
    "#     ax.set_title(\"\" + i+ \"heart disease\")\n",
    "#     num+=1\n",
    "    print(i)\n",
    "    print(df.HeartDisease.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testEncryp import *\n",
    "\n",
    "# Scheme's parameters\n",
    "# polynomial modulus degree\n",
    "n = 2**4\n",
    "# ciphertext modulus\n",
    "q = 2**15\n",
    "# plaintext modulus\n",
    "t = 2**8\n",
    "# polynomial modulus\n",
    "poly_mod = np.array([1] + [0] * (n - 1) + [1])\n",
    "# Keygen\n",
    "pk, sk = keygen(n, q, poly_mod)\n",
    "# Encryption\n",
    "pt1, pt2 = 73, 20\n",
    "cst1, cst2 = 7, 5\n",
    "ct1 = encrypt(pk, n, q, t, poly_mod, pt1)\n",
    "ct2 = encrypt(pk, n, q, t, poly_mod, pt2)\n",
    "\n",
    "print(\"[+] Ciphertext ct1({}):\".format(pt1))\n",
    "print(\"\")\n",
    "print(\"\\t ct1_0:\", ct1[0])\n",
    "print(\"\\t ct1_1:\", ct1[1])\n",
    "print(\"\")\n",
    "print(\"[+] Ciphertext ct2({}):\".format(pt2))\n",
    "print(\"\")\n",
    "print(\"\\t ct1_0:\", ct2[0])\n",
    "print(\"\\t ct1_1:\", ct2[1])\n",
    "print(\"\")\n",
    "\n",
    "# Evaluation\n",
    "ct3 = add_plain(ct1, cst1, q, t, poly_mod)\n",
    "ct4 = mul_plain(ct2, cst2, q, t, poly_mod)\n",
    "\n",
    "# Decryption\n",
    "decrypted_ct3 = decrypt(sk, n, q, t, poly_mod, ct3)\n",
    "decrypted_ct4 = decrypt(sk, n, q, t, poly_mod, ct4)\n",
    "\n",
    "print(\"[+] Decrypted ct3(ct1 + {}): {}\".format(cst1, decrypted_ct3))\n",
    "print(\"[+] Decrypted ct4(ct2 * {}): {}\".format(cst2, decrypted_ct4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cac72e2ca1489f7157a7b4a660893ba3b03625a75143f8c8e6188cd9e63cd5e4"
  },
  "kernelspec": {
   "display_name": "fl_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
